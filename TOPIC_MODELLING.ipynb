{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic Modelling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from pprint import pprint\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "from gensim.models import LdaModel, LdaMulticore\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import nltk\n",
    "nltk.download('wordnet', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4911, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.read_csv('corpus.csv')\n",
    "corpus = corpus.drop_duplicates()\n",
    "corpus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Section_ID</th>\n",
       "      <th>Section_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cite-1</td>\n",
       "      <td>authority. this part is issued pursuant to 12 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cite-2</td>\n",
       "      <td>purpose this part prescribes standards under w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cite-3</td>\n",
       "      <td>scope. the standards set forth in this part ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cite-4</td>\n",
       "      <td>reservation of authority. the occ may determin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cite-43</td>\n",
       "      <td>obligation issued by an obligor not possessing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Section_ID                                       Section_Text\n",
       "0     Cite-1  authority. this part is issued pursuant to 12 ...\n",
       "1     Cite-2  purpose this part prescribes standards under w...\n",
       "2     Cite-3  scope. the standards set forth in this part ap...\n",
       "3     Cite-4  reservation of authority. the occ may determin...\n",
       "4    Cite-43  obligation issued by an obligor not possessing..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cleaning and lemmatizing docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result\n",
    "\n",
    "def clean_text(text):\n",
    "    text =  re.sub(r\"[^a-z0-9]\", \" \", text.lower())   \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed = corpus.Section_Text.apply(clean_text).apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    [author, issu, pursuant, seventh]\n",
       "1    [purpos, prescrib, standard, nation, bank, pur...\n",
       "2    [scope, standard, forth, appli, nation, bank, ...\n",
       "3    [reserv, author, determin, case, case, basi, n...\n",
       "4    [oblig, issu, obligor, possess, general, power...\n",
       "Name: Section_Text, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    authority. this part is issued pursuant to 12 ...\n",
       "1    purpose this part prescribes standards under w...\n",
       "2    scope. the standards set forth in this part ap...\n",
       "3    reservation of authority. the occ may determin...\n",
       "4    obligation issued by an obligor not possessing...\n",
       "Name: Section_Text, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.Section_Text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating bow corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# creating bag-of-word corpus\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in preprocessed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 1 (\"issu\"),  Occurances - 2.\n",
      "Word 4 (\"bank\"),  Occurances - 7.\n",
      "Word 6 (\"contain\"),  Occurances - 1.\n",
      "Word 9 (\"nation\"),  Occurances - 5.\n",
      "Word 22 (\"appli\"),  Occurances - 5.\n",
      "Word 27 (\"feder\"),  Occurances - 5.\n",
      "Word 36 (\"state\"),  Occurances - 3.\n",
      "Word 38 (\"subject\"),  Occurances - 1.\n",
      "Word 49 (\"determin\"),  Occurances - 2.\n",
      "Word 56 (\"paragraph\"),  Occurances - 1.\n",
      "Word 63 (\"section\"),  Occurances - 6.\n",
      "Word 67 (\"general\"),  Occurances - 2.\n",
      "Word 76 (\"requir\"),  Occurances - 3.\n",
      "Word 85 (\"applic\"),  Occurances - 9.\n",
      "Word 91 (\"combin\"),  Occurances - 1.\n",
      "Word 94 (\"credit\"),  Occurances - 1.\n",
      "Word 104 (\"follow\"),  Occurances - 1.\n",
      "Word 121 (\"provis\"),  Occurances - 1.\n",
      "Word 122 (\"public\"),  Occurances - 4.\n",
      "Word 128 (\"statutori\"),  Occurances - 1.\n",
      "Word 156 (\"shall\"),  Occurances - 1.\n",
      "Word 193 (\"institut\"),  Occurances - 1.\n",
      "Word 214 (\"rule\"),  Occurances - 1.\n",
      "Word 236 (\"organ\"),  Occurances - 2.\n",
      "Word 240 (\"busi\"),  Occurances - 1.\n",
      "Word 255 (\"relat\"),  Occurances - 1.\n",
      "Word 271 (\"cover\"),  Occurances - 1.\n",
      "Word 274 (\"compani\"),  Occurances - 1.\n",
      "Word 291 (\"legal\"),  Occurances - 2.\n",
      "Word 297 (\"separ\"),  Occurances - 1.\n",
      "Word 305 (\"conclud\"),  Occurances - 2.\n",
      "Word 314 (\"treat\"),  Occurances - 1.\n",
      "Word 326 (\"notic\"),  Occurances - 4.\n",
      "Word 339 (\"present\"),  Occurances - 2.\n",
      "Word 344 (\"transact\"),  Occurances - 1.\n",
      "Word 382 (\"result\"),  Occurances - 1.\n",
      "Word 384 (\"associ\"),  Occurances - 6.\n",
      "Word 389 (\"save\"),  Occurances - 6.\n",
      "Word 405 (\"part\"),  Occurances - 1.\n",
      "Word 419 (\"statut\"),  Occurances - 2.\n",
      "Word 453 (\"engag\"),  Occurances - 1.\n",
      "Word 460 (\"merger\"),  Occurances - 1.\n",
      "Word 537 (\"trust\"),  Occurances - 1.\n",
      "Word 631 (\"polici\"),  Occurances - 2.\n",
      "Word 668 (\"except\"),  Occurances - 1.\n",
      "Word 696 (\"supervisori\"),  Occurances - 2.\n",
      "Word 734 (\"process\"),  Occurances - 1.\n",
      "Word 773 (\"union\"),  Occurances - 1.\n",
      "Word 878 (\"interim\"),  Occurances - 6.\n",
      "Word 963 (\"signific\"),  Occurances - 2.\n",
      "Word 1200 (\"comment\"),  Occurances - 1.\n",
      "Word 1320 (\"novel\"),  Occurances - 2.\n"
     ]
    }
   ],
   "source": [
    "# bow document example\n",
    "index = 4310\n",
    "ex = bow_corpus[index]\n",
    "for i in range(len(ex)):\n",
    "    print(\"Word {} (\\\"{}\\\"),  Occurances - {}.\".format(ex[i][0], dictionary[ex[i][0]], ex[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### creaitng TF-IDF corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = models.TfidfModel(bow_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tfidf = tfidf[bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0.08045598595140308),\n",
       " (4, 0.09896513502771173),\n",
       " (6, 0.05877374788891292),\n",
       " (9, 0.13564750133198109),\n",
       " (22, 0.19975940808941667),\n",
       " (27, 0.10374349398314156),\n",
       " (36, 0.10351053252792156),\n",
       " (38, 0.03823172690952112),\n",
       " (49, 0.06782336468808096),\n",
       " (56, 0.0276611726337707),\n",
       " (63, 0.10869137589313682),\n",
       " (67, 0.0785855822653381),\n",
       " (76, 0.06343088439992764),\n",
       " (85, 0.2779455339514064),\n",
       " (91, 0.0779753402236377),\n",
       " (94, 0.03482970439821828),\n",
       " (104, 0.03730462288261047),\n",
       " (121, 0.04982873762762001),\n",
       " (122, 0.19851449852946293),\n",
       " (128, 0.09081652819818375),\n",
       " (156, 0.026751642802779432),\n",
       " (193, 0.03221530029032839),\n",
       " (214, 0.05065014650992854),\n",
       " (236, 0.11208602557667292),\n",
       " (240, 0.04276316505928335),\n",
       " (255, 0.04814301342534641),\n",
       " (271, 0.04786797230138649),\n",
       " (274, 0.046043189191121395),\n",
       " (291, 0.1280013799551643),\n",
       " (297, 0.06606598377077982),\n",
       " (305, 0.18083662685517451),\n",
       " (314, 0.075057071384233),\n",
       " (326, 0.1731894805314762),\n",
       " (339, 0.138323649035197),\n",
       " (344, 0.037844682986903425),\n",
       " (382, 0.05497004256954395),\n",
       " (384, 0.15386958866041617),\n",
       " (389, 0.16268166441918278),\n",
       " (405, 0.09249507041432177),\n",
       " (419, 0.1519652772678492),\n",
       " (453, 0.05754620977666402),\n",
       " (460, 0.08494592516980555),\n",
       " (537, 0.07012352552760363),\n",
       " (631, 0.11738949187307364),\n",
       " (668, 0.07069489772860214),\n",
       " (696, 0.1222501444742231),\n",
       " (734, 0.061394474527378416),\n",
       " (773, 0.08890133736793236),\n",
       " (878, 0.6153836053487217),\n",
       " (963, 0.1290471155811411),\n",
       " (1200, 0.08586287937119272),\n",
       " (1320, 0.22829954818981402)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_tfidf[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic Modelling using BOW  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_bow = LdaMulticore(bow_corpus, num_topics=20, id2word=dictionary, passes=2, workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.056*\"bank\" + 0.026*\"reserv\" + 0.022*\"section\" + 0.020*\"feder\" + 0.017*\"associ\" + 0.015*\"save\" + 0.015*\"paragraph\" + 0.014*\"leas\" + 0.011*\"capit\" + 0.011*\"payment\"\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.020*\"agreement\" + 0.019*\"account\" + 0.017*\"credit\" + 0.014*\"applic\" + 0.014*\"section\" + 0.013*\"inform\" + 0.013*\"loan\" + 0.012*\"requir\" + 0.012*\"file\" + 0.011*\"institut\"\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.043*\"bank\" + 0.026*\"mean\" + 0.018*\"compani\" + 0.016*\"section\" + 0.015*\"asset\" + 0.014*\"feder\" + 0.012*\"loan\" + 0.012*\"secur\" + 0.011*\"exposur\" + 0.011*\"save\"\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.029*\"applic\" + 0.020*\"account\" + 0.017*\"paragraph\" + 0.017*\"requir\" + 0.016*\"shall\" + 0.015*\"bank\" + 0.015*\"section\" + 0.014*\"invest\" + 0.012*\"provid\" + 0.012*\"notic\"\n",
      "\n",
      "Topic: 4 \n",
      "Words: 0.027*\"bank\" + 0.021*\"associ\" + 0.021*\"section\" + 0.019*\"save\" + 0.018*\"institut\" + 0.017*\"paragraph\" + 0.014*\"feder\" + 0.014*\"nation\" + 0.013*\"board\" + 0.012*\"risk\"\n",
      "\n",
      "Topic: 5 \n",
      "Words: 0.033*\"bank\" + 0.030*\"loan\" + 0.016*\"feder\" + 0.015*\"real\" + 0.013*\"servic\" + 0.013*\"section\" + 0.013*\"develop\" + 0.013*\"estat\" + 0.012*\"credit\" + 0.011*\"mean\"\n",
      "\n",
      "Topic: 6 \n",
      "Words: 0.033*\"bank\" + 0.031*\"parti\" + 0.025*\"director\" + 0.018*\"request\" + 0.014*\"board\" + 0.011*\"feder\" + 0.011*\"offic\" + 0.011*\"shall\" + 0.011*\"person\" + 0.011*\"file\"\n",
      "\n",
      "Topic: 7 \n",
      "Words: 0.023*\"shall\" + 0.019*\"associ\" + 0.017*\"section\" + 0.016*\"save\" + 0.015*\"feder\" + 0.015*\"notic\" + 0.015*\"requir\" + 0.013*\"request\" + 0.013*\"bank\" + 0.012*\"file\"\n",
      "\n",
      "Topic: 8 \n",
      "Words: 0.034*\"institut\" + 0.030*\"capit\" + 0.027*\"board\" + 0.021*\"regul\" + 0.017*\"bank\" + 0.016*\"feder\" + 0.016*\"associ\" + 0.016*\"save\" + 0.014*\"tier\" + 0.012*\"instrument\"\n",
      "\n",
      "Topic: 9 \n",
      "Words: 0.043*\"clear\" + 0.040*\"transact\" + 0.038*\"secur\" + 0.025*\"bank\" + 0.020*\"member\" + 0.018*\"swap\" + 0.017*\"section\" + 0.016*\"requir\" + 0.012*\"risk\" + 0.011*\"feder\"\n",
      "\n",
      "Topic: 10 \n",
      "Words: 0.045*\"bank\" + 0.023*\"state\" + 0.023*\"section\" + 0.020*\"foreign\" + 0.016*\"activ\" + 0.016*\"branch\" + 0.016*\"board\" + 0.013*\"deposit\" + 0.013*\"unit\" + 0.012*\"requir\"\n",
      "\n",
      "Topic: 11 \n",
      "Words: 0.034*\"associ\" + 0.032*\"save\" + 0.031*\"asset\" + 0.016*\"feder\" + 0.016*\"credit\" + 0.016*\"bank\" + 0.013*\"fund\" + 0.013*\"section\" + 0.012*\"loan\" + 0.011*\"secur\"\n",
      "\n",
      "Topic: 12 \n",
      "Words: 0.056*\"save\" + 0.055*\"associ\" + 0.053*\"bank\" + 0.052*\"feder\" + 0.048*\"nation\" + 0.017*\"risk\" + 0.017*\"capit\" + 0.014*\"requir\" + 0.010*\"section\" + 0.009*\"applic\"\n",
      "\n",
      "Topic: 13 \n",
      "Words: 0.032*\"risk\" + 0.029*\"exposur\" + 0.022*\"institut\" + 0.018*\"bank\" + 0.018*\"board\" + 0.018*\"credit\" + 0.018*\"associ\" + 0.017*\"regul\" + 0.016*\"posit\" + 0.015*\"save\"\n",
      "\n",
      "Topic: 14 \n",
      "Words: 0.036*\"bank\" + 0.029*\"save\" + 0.023*\"associ\" + 0.022*\"feder\" + 0.016*\"institut\" + 0.013*\"depositori\" + 0.012*\"mean\" + 0.012*\"loan\" + 0.011*\"area\" + 0.011*\"year\"\n",
      "\n",
      "Topic: 15 \n",
      "Words: 0.028*\"exposur\" + 0.028*\"bank\" + 0.020*\"risk\" + 0.015*\"credit\" + 0.015*\"section\" + 0.014*\"transact\" + 0.013*\"nation\" + 0.012*\"invest\" + 0.010*\"paragraph\" + 0.010*\"requir\"\n",
      "\n",
      "Topic: 16 \n",
      "Words: 0.039*\"bank\" + 0.033*\"feder\" + 0.023*\"associ\" + 0.021*\"save\" + 0.018*\"nation\" + 0.016*\"requir\" + 0.015*\"section\" + 0.010*\"agenc\" + 0.009*\"financi\" + 0.009*\"applic\"\n",
      "\n",
      "Topic: 17 \n",
      "Words: 0.022*\"associ\" + 0.019*\"credit\" + 0.019*\"save\" + 0.017*\"bank\" + 0.015*\"feder\" + 0.011*\"section\" + 0.011*\"paragraph\" + 0.011*\"exposur\" + 0.010*\"secur\" + 0.009*\"capit\"\n",
      "\n",
      "Topic: 18 \n",
      "Words: 0.043*\"bank\" + 0.029*\"state\" + 0.016*\"insur\" + 0.012*\"institut\" + 0.012*\"nation\" + 0.010*\"includ\" + 0.010*\"secur\" + 0.010*\"loan\" + 0.010*\"cover\" + 0.010*\"section\"\n",
      "\n",
      "Topic: 19 \n",
      "Words: 0.058*\"bank\" + 0.024*\"exposur\" + 0.014*\"credit\" + 0.013*\"board\" + 0.013*\"institut\" + 0.012*\"custom\" + 0.012*\"loan\" + 0.012*\"regul\" + 0.012*\"invest\" + 0.010*\"section\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_bow.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}\\n'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic Modelling using TF-IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_tfidf = LdaMulticore(corpus_tfidf, num_topics=20, id2word=dictionary, passes=2, workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Word: 0.008*\"convers\" + 0.007*\"secur\" + 0.007*\"bank\" + 0.007*\"share\" + 0.006*\"proxi\" + 0.006*\"member\" + 0.006*\"offer\" + 0.006*\"feder\" + 0.006*\"vote\" + 0.005*\"person\"\n",
      "\n",
      "Topic: 1 \n",
      "Word: 0.011*\"author\" + 0.010*\"bank\" + 0.009*\"save\" + 0.009*\"associ\" + 0.008*\"loan\" + 0.007*\"feder\" + 0.007*\"section\" + 0.007*\"nation\" + 0.007*\"amend\" + 0.006*\"compani\"\n",
      "\n",
      "Topic: 2 \n",
      "Word: 0.012*\"author\" + 0.009*\"bank\" + 0.008*\"apprais\" + 0.008*\"state\" + 0.008*\"capit\" + 0.007*\"feder\" + 0.007*\"nation\" + 0.006*\"offic\" + 0.006*\"develop\" + 0.006*\"save\"\n",
      "\n",
      "Topic: 3 \n",
      "Word: 0.010*\"hear\" + 0.009*\"parti\" + 0.009*\"file\" + 0.009*\"request\" + 0.008*\"judg\" + 0.008*\"bank\" + 0.007*\"motion\" + 0.007*\"comptrol\" + 0.007*\"shall\" + 0.007*\"order\"\n",
      "\n",
      "Topic: 4 \n",
      "Word: 0.008*\"applic\" + 0.008*\"agreement\" + 0.007*\"institut\" + 0.007*\"inform\" + 0.007*\"disclosur\" + 0.007*\"bank\" + 0.006*\"insur\" + 0.006*\"save\" + 0.006*\"board\" + 0.006*\"account\"\n",
      "\n",
      "Topic: 5 \n",
      "Word: 0.009*\"save\" + 0.008*\"associ\" + 0.008*\"bank\" + 0.008*\"file\" + 0.008*\"feder\" + 0.006*\"nation\" + 0.006*\"section\" + 0.006*\"notic\" + 0.006*\"shall\" + 0.005*\"requir\"\n",
      "\n",
      "Topic: 6 \n",
      "Word: 0.021*\"author\" + 0.010*\"bank\" + 0.008*\"secur\" + 0.007*\"transact\" + 0.007*\"nation\" + 0.006*\"feder\" + 0.006*\"associ\" + 0.006*\"invest\" + 0.006*\"save\" + 0.006*\"fiduciari\"\n",
      "\n",
      "Topic: 7 \n",
      "Word: 0.009*\"exposur\" + 0.008*\"capit\" + 0.007*\"associ\" + 0.007*\"save\" + 0.006*\"nation\" + 0.006*\"bank\" + 0.006*\"account\" + 0.006*\"feder\" + 0.006*\"stock\" + 0.005*\"inform\"\n",
      "\n",
      "Topic: 8 \n",
      "Word: 0.010*\"institut\" + 0.009*\"board\" + 0.009*\"exposur\" + 0.008*\"bank\" + 0.008*\"regul\" + 0.008*\"compani\" + 0.008*\"save\" + 0.007*\"associ\" + 0.007*\"invest\" + 0.007*\"risk\"\n",
      "\n",
      "Topic: 9 \n",
      "Word: 0.008*\"mean\" + 0.008*\"total\" + 0.008*\"bank\" + 0.007*\"associ\" + 0.007*\"save\" + 0.007*\"subpart\" + 0.007*\"asset\" + 0.006*\"nation\" + 0.006*\"section\" + 0.006*\"agreement\"\n",
      "\n",
      "Topic: 10 \n",
      "Word: 0.012*\"bank\" + 0.011*\"exposur\" + 0.010*\"risk\" + 0.009*\"save\" + 0.009*\"branch\" + 0.009*\"associ\" + 0.008*\"feder\" + 0.008*\"reserv\" + 0.008*\"institut\" + 0.007*\"nation\"\n",
      "\n",
      "Topic: 11 \n",
      "Word: 0.018*\"capit\" + 0.015*\"exposur\" + 0.015*\"tier\" + 0.013*\"securit\" + 0.011*\"risk\" + 0.010*\"asset\" + 0.010*\"associ\" + 0.010*\"save\" + 0.009*\"credit\" + 0.009*\"mean\"\n",
      "\n",
      "Topic: 12 \n",
      "Word: 0.010*\"secur\" + 0.008*\"bank\" + 0.008*\"loan\" + 0.007*\"associ\" + 0.007*\"save\" + 0.007*\"transact\" + 0.007*\"nation\" + 0.007*\"feder\" + 0.007*\"board\" + 0.006*\"invest\"\n",
      "\n",
      "Topic: 13 \n",
      "Word: 0.012*\"swap\" + 0.008*\"bank\" + 0.008*\"margin\" + 0.008*\"feder\" + 0.007*\"request\" + 0.007*\"file\" + 0.007*\"board\" + 0.006*\"clear\" + 0.006*\"associ\" + 0.006*\"save\"\n",
      "\n",
      "Topic: 14 \n",
      "Word: 0.011*\"bank\" + 0.010*\"feder\" + 0.010*\"custom\" + 0.009*\"deposit\" + 0.008*\"purpos\" + 0.008*\"nation\" + 0.008*\"insur\" + 0.008*\"associ\" + 0.007*\"section\" + 0.007*\"save\"\n",
      "\n",
      "Topic: 15 \n",
      "Word: 0.015*\"account\" + 0.009*\"bank\" + 0.009*\"compani\" + 0.007*\"deposit\" + 0.007*\"board\" + 0.006*\"share\" + 0.006*\"state\" + 0.006*\"secur\" + 0.006*\"organ\" + 0.006*\"holder\"\n",
      "\n",
      "Topic: 16 \n",
      "Word: 0.008*\"bank\" + 0.007*\"loan\" + 0.006*\"institut\" + 0.006*\"servic\" + 0.006*\"feder\" + 0.006*\"save\" + 0.006*\"associ\" + 0.006*\"risk\" + 0.005*\"document\" + 0.005*\"capit\"\n",
      "\n",
      "Topic: 17 \n",
      "Word: 0.014*\"associ\" + 0.014*\"save\" + 0.011*\"feder\" + 0.011*\"bank\" + 0.010*\"nation\" + 0.009*\"branch\" + 0.008*\"area\" + 0.008*\"mean\" + 0.007*\"institut\" + 0.007*\"offic\"\n",
      "\n",
      "Topic: 18 \n",
      "Word: 0.011*\"retail\" + 0.010*\"forex\" + 0.009*\"exchang\" + 0.008*\"save\" + 0.008*\"associ\" + 0.008*\"bank\" + 0.007*\"nation\" + 0.007*\"mean\" + 0.007*\"commod\" + 0.006*\"feder\"\n",
      "\n",
      "Topic: 19 \n",
      "Word: 0.010*\"bank\" + 0.010*\"associ\" + 0.009*\"save\" + 0.008*\"feder\" + 0.007*\"nation\" + 0.006*\"communic\" + 0.006*\"busi\" + 0.006*\"shall\" + 0.006*\"applic\" + 0.006*\"institut\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_tfidf.print_topics(-1):\n",
    "    print('Topic: {} \\nWord: {}\\n'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
